{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cs9E_R5yD48u"
   },
   "source": [
    "# **Assignment \\#2**: Machine Learning MC886/MO444\n",
    "University of Campinas (UNICAMP), Institute of Computing (IC)\n",
    "\n",
    "Prof. Sandra Avila, 2022s2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tFS9Oum_RJX9",
    "outputId": "bfa0da7b-070d-49d9-9f2f-c86a2831da5a"
   },
   "outputs": [],
   "source": [
    "# TODO: RA & Name \n",
    "print('RA:181980 ' + 'Bruno Martinez de Farias')\n",
    "print('RA:220129 ' + 'Leonardo Mazzamboni Colussi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVGH2s7fD_03"
   },
   "source": [
    "## Objective\n",
    "\n",
    "Explore **linear regression** and **logistic regression** alternatives and come up with the best possible model for the problems, avoiding overfitting. In particular, predict the performance of students from public schools in the state of São Paulo based on socioeconomic data from SARESP (School Performance Assessment System of the State of São Paulo, or Sistema de Avaliação de Rendimento Escolar do Estado de São Paulo) 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3XDZRGqEwsk"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "These data were aggregated from [Open Data Platform of the Secretary of Education of the State of São Paulo](https://dados.educacao.sp.gov.br/) (*Portal de Dados Abertos da Secretaria da Educação do Estado de São Paulo*). The dataset is based on two data sources: [SARESP questionnaire](https://dados.educacao.sp.gov.br/dataset/question%C3%A1rios-saresp) and [SARESP test](https://dados.educacao.sp.gov.br/dataset/profici%C3%AAncia-do-sistema-de-avalia%C3%A7%C3%A3o-de-rendimento-escolar-do-estado-de-s%C3%A3o-paulo-saresp-por), conducted in 2021 with students from the 5th and 9th year of Primary School and 3rd year of Highschool. The questionnaire comprehends 63 socio-economical questions, and it is available at the [link](https://dados.educacao.sp.gov.br/sites/default/files/Saresp_Quest_2021_Perguntas_Alunos.pdf ) ([English version](https://docs.google.com/document/d/1GUax3wwYxA43d3iNOiyCRImeCHgx8vUJrHlSzzYIXA4/edit?usp=sharing)), and the test is composed of questions of Portuguese, Mathematics, and Natural Sciences.\n",
    "\n",
    "\n",
    "**Data Dictionary**:\n",
    "\n",
    "- **CD_ALUNO**: Student ID;\n",
    "\n",
    "- **CODESC**: School ID;\n",
    "\n",
    "- **NOMESC**: School Name;\n",
    "\n",
    "- **RegiaoMetropolitana**: Metropolitan region;\n",
    "\n",
    "- **DE**: Name of the Education Board;\n",
    "\n",
    "- **CODMUN**: City ID;\n",
    "\n",
    "- **MUN**: City name;\n",
    "\n",
    "- **SERIE_ANO**: Scholar year;\n",
    "\n",
    "- **TURMA**: Class;\n",
    "\n",
    "- **TP_SEXO**: Sex (Female/Male);\n",
    "\n",
    "- **DT_NASCIMENTO**: Birth date;\n",
    "\n",
    "- **PERIODO**: Period of study (morning, afternoon, evening);\n",
    "\n",
    "- **Tem_Nec**: Whether student has any special needs (1 = yes, 0 = no);\n",
    "\n",
    "- **NEC_ESP_1** - **NEC_ESP_5**: Student disabilities;\n",
    "\n",
    "- **Tipo_PROVA**: Exam type (A = Enlarged, B = Braile, C = Common);\n",
    "\n",
    "- **QN**: Student answer to the question N (N= 1, ... , 63), see  questions in [questionnaire](https://dados.educacao.sp.gov.br/sites/default/files/Saresp_Quest_2021_Perguntas_Alunos.pdf ) ([English version](https://docs.google.com/document/d/1GUax3wwYxA43d3iNOiyCRImeCHgx8vUJrHlSzzYIXA4/edit?usp=sharing));\n",
    "\n",
    "- **porc_ACERT_lp**: Percentage of correct answers in the Portuguese test;\n",
    "\n",
    "- **porc_ACERT_MAT**: Percentage of correct answers in the Mathematics test;\n",
    "\n",
    "- **porc_ACERT_CIE**: Percentage of correct answers in the Natural Sciences test;\n",
    "\n",
    "- **nivel_profic_lp**: Proficiency level in the Portuguese test;\n",
    "\n",
    "- **nivel_profic_mat**: Proficiency level in the Mathematics test;\n",
    "\n",
    "- **nivel_profic_cie**:  Proficiency level in the Natural Sciences test.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "You must respect the following training/test split:\n",
    "- SARESP_train.csv\n",
    "- SARESP_test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FAA8hsZUseO"
   },
   "source": [
    "## Linear Regression\n",
    "\n",
    "This part of the assignment aims to predict students' performance on Portuguese, Mathematics, and Natural Sciences tests (target values: `porc_ACERT_lp`, `porc_ACERT_MAT`, and  `porc_ACERT_CIE`) based on their socioeconomic data. Then, at this point, you have to **drop the columns `nivel_profic_lp`, `nivel_profic_mat`** and **`nivel_profic_cie`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d495CmpCltx"
   },
   "source": [
    "### Activities\n",
    "\n",
    "1. (3.5 points) Perform Linear Regression. You should implement your solution and compare it with ```sklearn.linear_model.SGDRegressor``` (linear model fitted by minimizing a regularized empirical loss with SGD, http://scikit-learn.org). Keep in mind that friends don't let friends use testing data for training :-)\n",
    "\n",
    "Note: Before we start an ML project, we always conduct a brief exploratory analysis :D \n",
    "\n",
    "Some factors to consider: Are there any outliers? Are there missing values? How will you handle categorical variables? Are there any features with low correlation with the target variables? What happens if you drop them?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "3y0QxxH1KgE1",
    "outputId": "d181b90f-ad63-4918-8413-8179854ed38e"
   },
   "outputs": [],
   "source": [
    "# TODO: Load and preprocess your dataset.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random as rand\n",
    "import warnings\n",
    "import zipfile\n",
    "import os \n",
    "from datetime import datetime, date\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder , RobustScaler, MaxAbsScaler\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eDD26lSehqws"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y3CYfc05XfKU",
    "outputId": "74a73898-729a-4e89-8d65-52367eca1db9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120596, 88), 17424)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('SARESP_train.csv')\n",
    "df.shape, df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_vipomtWbFOT",
    "outputId": "fdd36fd9-6677-4eb3-8ec6-e3c230d3b94c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 103172 entries, 0 to 120594\n",
      "Data columns (total 88 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   CD_ALUNO             103172 non-null  int64  \n",
      " 1   NOMESC               103172 non-null  object \n",
      " 2   Q1                   103172 non-null  object \n",
      " 3   Q2                   103172 non-null  object \n",
      " 4   Q3                   103172 non-null  object \n",
      " 5   Q4                   103172 non-null  object \n",
      " 6   Q5                   103172 non-null  object \n",
      " 7   Q6                   103172 non-null  object \n",
      " 8   Q7                   103172 non-null  object \n",
      " 9   Q8                   103172 non-null  object \n",
      " 10  Q9                   103172 non-null  object \n",
      " 11  Q10                  103172 non-null  object \n",
      " 12  Q11                  103172 non-null  object \n",
      " 13  Q12                  103172 non-null  object \n",
      " 14  Q13                  103172 non-null  object \n",
      " 15  Q14                  103172 non-null  object \n",
      " 16  Q15                  103172 non-null  object \n",
      " 17  Q16                  103172 non-null  object \n",
      " 18  Q17                  103172 non-null  object \n",
      " 19  Q18                  103172 non-null  object \n",
      " 20  Q19                  103172 non-null  object \n",
      " 21  Q20                  103172 non-null  object \n",
      " 22  Q21                  103172 non-null  object \n",
      " 23  Q22                  103172 non-null  object \n",
      " 24  Q23                  103172 non-null  object \n",
      " 25  Q24                  103172 non-null  object \n",
      " 26  Q25                  103172 non-null  object \n",
      " 27  Q26                  103172 non-null  object \n",
      " 28  Q27                  103172 non-null  object \n",
      " 29  Q28                  103172 non-null  object \n",
      " 30  Q29                  103172 non-null  object \n",
      " 31  Q30                  103172 non-null  object \n",
      " 32  Q31                  103172 non-null  object \n",
      " 33  Q32                  103172 non-null  object \n",
      " 34  Q33                  103172 non-null  object \n",
      " 35  Q34                  103172 non-null  object \n",
      " 36  Q35                  103172 non-null  object \n",
      " 37  Q36                  103172 non-null  object \n",
      " 38  Q37                  103172 non-null  object \n",
      " 39  Q38                  103172 non-null  object \n",
      " 40  Q39                  103172 non-null  object \n",
      " 41  Q40                  103172 non-null  object \n",
      " 42  Q41                  103172 non-null  object \n",
      " 43  Q42                  103172 non-null  object \n",
      " 44  Q43                  103172 non-null  object \n",
      " 45  Q44                  103172 non-null  object \n",
      " 46  Q45                  103172 non-null  object \n",
      " 47  Q46                  103172 non-null  object \n",
      " 48  Q47                  103172 non-null  object \n",
      " 49  Q48                  103172 non-null  object \n",
      " 50  Q49                  103172 non-null  object \n",
      " 51  Q50                  103172 non-null  object \n",
      " 52  Q51                  103172 non-null  object \n",
      " 53  Q52                  103172 non-null  object \n",
      " 54  Q53                  103172 non-null  object \n",
      " 55  Q54                  103172 non-null  object \n",
      " 56  Q55                  103172 non-null  object \n",
      " 57  Q56                  103172 non-null  object \n",
      " 58  Q57                  103172 non-null  object \n",
      " 59  Q58                  103172 non-null  object \n",
      " 60  Q59                  103172 non-null  object \n",
      " 61  Q60                  103172 non-null  object \n",
      " 62  Q61                  103172 non-null  object \n",
      " 63  Q62                  103172 non-null  object \n",
      " 64  Q63                  103172 non-null  object \n",
      " 65  RegiaoMetropolitana  103172 non-null  object \n",
      " 66  DE                   103172 non-null  object \n",
      " 67  CODMUN               103172 non-null  int64  \n",
      " 68  MUN                  103172 non-null  object \n",
      " 69  CODESC               103172 non-null  int64  \n",
      " 70  SERIE_ANO            103172 non-null  object \n",
      " 71  TURMA                103172 non-null  object \n",
      " 72  TP_SEXO              103172 non-null  object \n",
      " 73  DT_NASCIMENTO        103172 non-null  object \n",
      " 74  PERIODO              103172 non-null  object \n",
      " 75  NEC_ESP_1            1577 non-null    object \n",
      " 76  NEC_ESP_2            68 non-null      object \n",
      " 77  NEC_ESP_3            46 non-null      object \n",
      " 78  NEC_ESP_4            1 non-null       object \n",
      " 79  NEC_ESP_5            0 non-null       float64\n",
      " 80  Tipo_PROVA           103172 non-null  object \n",
      " 81  Tem_Nec              103172 non-null  int64  \n",
      " 82  porc_ACERT_lp        103172 non-null  float64\n",
      " 83  porc_ACERT_MAT       103172 non-null  float64\n",
      " 84  porc_ACERT_CIE       103172 non-null  float64\n",
      " 85  nivel_profic_lp      103172 non-null  object \n",
      " 86  nivel_profic_mat     103172 non-null  object \n",
      " 87  nivel_profic_cie     103172 non-null  object \n",
      "dtypes: float64(4), int64(4), object(80)\n",
      "memory usage: 70.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.drop_duplicates(inplace = True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SG_UF</th>\n",
       "      <th>CO_MUNICIPIO</th>\n",
       "      <th>CO_ENTIDADE</th>\n",
       "      <th>QT_MAT_BAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RO</td>\n",
       "      <td>1100015</td>\n",
       "      <td>11022558</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RO</td>\n",
       "      <td>1100015</td>\n",
       "      <td>11024275</td>\n",
       "      <td>231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RO</td>\n",
       "      <td>1100015</td>\n",
       "      <td>11024291</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RO</td>\n",
       "      <td>1100015</td>\n",
       "      <td>11024372</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RO</td>\n",
       "      <td>1100015</td>\n",
       "      <td>11024666</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SG_UF  CO_MUNICIPIO  CO_ENTIDADE  QT_MAT_BAS\n",
       "0    RO       1100015     11022558         8.0\n",
       "1    RO       1100015     11024275       231.0\n",
       "2    RO       1100015     11024291        10.0\n",
       "3    RO       1100015     11024372       104.0\n",
       "4    RO       1100015     11024666       173.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SG_UF</th>\n",
       "      <th>CO_MUNICIPIO</th>\n",
       "      <th>CO_ENTIDADE</th>\n",
       "      <th>QT_MAT_BAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP</td>\n",
       "      <td>3500105</td>\n",
       "      <td>35030806</td>\n",
       "      <td>699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP</td>\n",
       "      <td>3500105</td>\n",
       "      <td>35031045</td>\n",
       "      <td>557.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP</td>\n",
       "      <td>3500105</td>\n",
       "      <td>35031082</td>\n",
       "      <td>952.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP</td>\n",
       "      <td>3500105</td>\n",
       "      <td>35031100</td>\n",
       "      <td>239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP</td>\n",
       "      <td>3500105</td>\n",
       "      <td>35031112</td>\n",
       "      <td>656.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SG_UF  CO_MUNICIPIO  CO_ENTIDADE  QT_MAT_BAS\n",
       "0    SP       3500105     35030806       699.0\n",
       "1    SP       3500105     35031045       557.0\n",
       "2    SP       3500105     35031082       952.0\n",
       "3    SP       3500105     35031100       239.0\n",
       "4    SP       3500105     35031112       656.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "headers = ['SG_UF', 'CO_ENTIDADE', 'CO_MUNICIPIO', 'QT_MAT_BAS']\n",
    "\n",
    "with zipfile.ZipFile('microdados_censo_escolar_2021.zip') as zip:\n",
    "    with zip.open('2021/dados/microdados_ed_basica_2021.csv') as myZip:\n",
    "        df_mec = pd.read_csv(myZip,\n",
    "                             encoding = 'latin-1', \n",
    "                             sep = ';',\n",
    "                             usecols = headers) \n",
    "        \n",
    "df_mec_sp = df_mec[df_mec['SG_UF'] == 'SP'].dropna().reset_index(drop = True)\n",
    "\n",
    "display(df_mec.head(), df_mec_sp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO_MUNICIPIO</th>\n",
       "      <th>MAT_PER_MUN</th>\n",
       "      <th>ESC_PER_MUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3500105</td>\n",
       "      <td>7248.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3500204</td>\n",
       "      <td>839.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3500303</td>\n",
       "      <td>7287.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3500402</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3500501</td>\n",
       "      <td>3429.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CO_MUNICIPIO  MAT_PER_MUN  ESC_PER_MUN\n",
       "0       3500105       7248.0           26\n",
       "1       3500204        839.0            5\n",
       "2       3500303       7287.0           26\n",
       "3       3500402       1092.0            8\n",
       "4       3500501       3429.0           19"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mec_sp = df_mec_sp\\\n",
    "    .groupby('CO_MUNICIPIO')['QT_MAT_BAS'] \\\n",
    "    .agg(MAT_PER_MUN = 'sum', ESC_PER_MUN = 'count')\\\n",
    "    .reset_index() \n",
    "\n",
    "df_mec_sp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mec = pd.merge(df_mec, \n",
    "                  df_mec_sp, \n",
    "                  how = 'left', \n",
    "                  on = 'CO_MUNICIPIO')\n",
    "\n",
    "df_mec = df_mec[df_mec['SG_UF'] == 'SP'].drop('SG_UF', axis = 1)\n",
    "\n",
    "df_mec.rename(columns = {'CO_ENTIDADE': 'CODESC'}, inplace = True)\n",
    "df_mec['CODESC'] = df_mec['CODESC'].apply(lambda x: str(x)[2:]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BS9d6hHAecEK",
    "outputId": "d585d5b8-50da-4ae9-90cb-6d845f31b797"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((103172, 90), 0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df, df_mec, how = 'left', on = 'CODESC').drop(['CODMUN','CO_MUNICIPIO'], axis = 1)\n",
    "teste.shape, df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 103172 entries, 0 to 120594\n",
      "Data columns (total 88 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   CD_ALUNO             103172 non-null  int64  \n",
      " 1   NOMESC               103172 non-null  object \n",
      " 2   Q1                   103172 non-null  object \n",
      " 3   Q2                   103172 non-null  object \n",
      " 4   Q3                   103172 non-null  object \n",
      " 5   Q4                   103172 non-null  object \n",
      " 6   Q5                   103172 non-null  object \n",
      " 7   Q6                   103172 non-null  object \n",
      " 8   Q7                   103172 non-null  object \n",
      " 9   Q8                   103172 non-null  object \n",
      " 10  Q9                   103172 non-null  object \n",
      " 11  Q10                  103172 non-null  object \n",
      " 12  Q11                  103172 non-null  object \n",
      " 13  Q12                  103172 non-null  object \n",
      " 14  Q13                  103172 non-null  object \n",
      " 15  Q14                  103172 non-null  object \n",
      " 16  Q15                  103172 non-null  object \n",
      " 17  Q16                  103172 non-null  object \n",
      " 18  Q17                  103172 non-null  object \n",
      " 19  Q18                  103172 non-null  object \n",
      " 20  Q19                  103172 non-null  object \n",
      " 21  Q20                  103172 non-null  object \n",
      " 22  Q21                  103172 non-null  object \n",
      " 23  Q22                  103172 non-null  object \n",
      " 24  Q23                  103172 non-null  object \n",
      " 25  Q24                  103172 non-null  object \n",
      " 26  Q25                  103172 non-null  object \n",
      " 27  Q26                  103172 non-null  object \n",
      " 28  Q27                  103172 non-null  object \n",
      " 29  Q28                  103172 non-null  object \n",
      " 30  Q29                  103172 non-null  object \n",
      " 31  Q30                  103172 non-null  object \n",
      " 32  Q31                  103172 non-null  object \n",
      " 33  Q32                  103172 non-null  object \n",
      " 34  Q33                  103172 non-null  object \n",
      " 35  Q34                  103172 non-null  object \n",
      " 36  Q35                  103172 non-null  object \n",
      " 37  Q36                  103172 non-null  object \n",
      " 38  Q37                  103172 non-null  object \n",
      " 39  Q38                  103172 non-null  object \n",
      " 40  Q39                  103172 non-null  object \n",
      " 41  Q40                  103172 non-null  object \n",
      " 42  Q41                  103172 non-null  object \n",
      " 43  Q42                  103172 non-null  object \n",
      " 44  Q43                  103172 non-null  object \n",
      " 45  Q44                  103172 non-null  object \n",
      " 46  Q45                  103172 non-null  object \n",
      " 47  Q46                  103172 non-null  object \n",
      " 48  Q47                  103172 non-null  object \n",
      " 49  Q48                  103172 non-null  object \n",
      " 50  Q49                  103172 non-null  object \n",
      " 51  Q50                  103172 non-null  object \n",
      " 52  Q51                  103172 non-null  object \n",
      " 53  Q52                  103172 non-null  object \n",
      " 54  Q53                  103172 non-null  object \n",
      " 55  Q54                  103172 non-null  object \n",
      " 56  Q55                  103172 non-null  object \n",
      " 57  Q56                  103172 non-null  object \n",
      " 58  Q57                  103172 non-null  object \n",
      " 59  Q58                  103172 non-null  object \n",
      " 60  Q59                  103172 non-null  object \n",
      " 61  Q60                  103172 non-null  object \n",
      " 62  Q61                  103172 non-null  object \n",
      " 63  Q62                  103172 non-null  object \n",
      " 64  Q63                  103172 non-null  object \n",
      " 65  RegiaoMetropolitana  103172 non-null  object \n",
      " 66  DE                   103172 non-null  object \n",
      " 67  CODMUN               103172 non-null  int64  \n",
      " 68  MUN                  103172 non-null  object \n",
      " 69  CODESC               103172 non-null  int64  \n",
      " 70  SERIE_ANO            103172 non-null  object \n",
      " 71  TURMA                103172 non-null  object \n",
      " 72  TP_SEXO              103172 non-null  object \n",
      " 73  DT_NASCIMENTO        103172 non-null  object \n",
      " 74  PERIODO              103172 non-null  object \n",
      " 75  NEC_ESP_1            1577 non-null    object \n",
      " 76  NEC_ESP_2            68 non-null      object \n",
      " 77  NEC_ESP_3            46 non-null      object \n",
      " 78  NEC_ESP_4            1 non-null       object \n",
      " 79  NEC_ESP_5            0 non-null       float64\n",
      " 80  Tipo_PROVA           103172 non-null  object \n",
      " 81  Tem_Nec              103172 non-null  int64  \n",
      " 82  porc_ACERT_lp        103172 non-null  float64\n",
      " 83  porc_ACERT_MAT       103172 non-null  float64\n",
      " 84  porc_ACERT_CIE       103172 non-null  float64\n",
      " 85  nivel_profic_lp      103172 non-null  object \n",
      " 86  nivel_profic_mat     103172 non-null  object \n",
      " 87  nivel_profic_cie     103172 non-null  object \n",
      "dtypes: float64(4), int64(4), object(80)\n",
      "memory usage: 70.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9SGGsN09lXJ6",
    "outputId": "ec906ea8-6790-4b81-c245-474d4324ce82"
   },
   "outputs": [],
   "source": [
    "df['NEC_ESP_1'].unique(), df['NEC_ESP_2'].unique(), df['NEC_ESP_3'].unique(), df['NEC_ESP_4'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5yLjmxkzy5AA"
   },
   "outputs": [],
   "source": [
    "cond_deficientes = ((df['NEC_ESP_1'].isna() == False) & (df['NEC_ESP_1'] != 'ALTAS HABILIDADES/SUPERDOTACAO')) | (df['NEC_ESP_2'].isna() == False) | (df['NEC_ESP_3'].isna() == False) | (df['NEC_ESP_4'].isna() == False)\n",
    "cond_superdotados = df['NEC_ESP_1'] == 'ALTAS HABILIDADES/SUPERDOTACAO'\n",
    "\n",
    "idx_deficientes = df[cond_deficientes].index\n",
    "idx_superdotados = df[cond_superdotados].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yvp-2j3knIJV",
    "outputId": "f62e1fff-1925-4ed3-804f-89c63d5cfb34"
   },
   "outputs": [],
   "source": [
    "df[['porc_ACERT_MAT', 'porc_ACERT_CIE', 'porc_ACERT_lp']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DWjEEMghqV63",
    "outputId": "9300fd76-44e6-4ea5-b816-8c213e04aa12"
   },
   "outputs": [],
   "source": [
    "df[cond_deficientes][['porc_ACERT_MAT', 'porc_ACERT_CIE', 'porc_ACERT_lp']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-cUVQT9zF5l",
    "outputId": "671e53c8-c18a-439b-f420-3178092e1fd6"
   },
   "outputs": [],
   "source": [
    "df[cond_superdotados][['porc_ACERT_MAT', 'porc_ACERT_CIE', 'porc_ACERT_lp']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W6Q0khPwNC_1"
   },
   "outputs": [],
   "source": [
    "# A: has any disability\n",
    "# B: is gifted\n",
    "# C: has no disability\n",
    "\n",
    "df['disability'] = ['C' if i in idx_deficientes else 'B' if i in idx_superdotados else 'A' for i in df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kS8cv-H8w5Nr"
   },
   "outputs": [],
   "source": [
    "def age(birth_dt):\n",
    "    today = date.today()\n",
    "    return today.year - birth_dt.year - ((today.month, today.day) < (birth_dt.month, birth_dt.day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5NH-r5m0qdwu"
   },
   "outputs": [],
   "source": [
    "df['Age'] = pd.to_datetime(df['DT_NASCIMENTO']).apply(lambda x: age(x))\n",
    "df[['CODMUN', 'CODESC']] = df[['CODMUN', 'CODESC']].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qusjj0KWbWjV",
    "outputId": "0e84a22c-3ce5-4376-f3af-355b90cae5a1"
   },
   "outputs": [],
   "source": [
    "drop_cols_categ = ['NOMESC', 'MUN', 'DT_NASCIMENTO', 'NEC_ESP_1', 'NEC_ESP_2', 'NEC_ESP_3', 'NEC_ESP_4', 'TURMA', 'nivel_profic_lp', 'nivel_profic_mat', 'nivel_profic_cie']\n",
    "drop_cols_numeric = ['CD_ALUNO', 'NEC_ESP_5','Tem_Nec']\n",
    "\n",
    "df_categ = df.select_dtypes(include = 'object').drop(drop_cols_categ, axis = 1)\n",
    "df_num = df.select_dtypes(include = 'number').drop(drop_cols_numeric, axis = 1)\n",
    "\n",
    "df_categ.shape, df_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "id": "jSFdHd6MiwvT",
    "outputId": "35fe136c-f9c1-41f9-9ee3-9c03687ec46e"
   },
   "outputs": [],
   "source": [
    "df_categ.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lIeR3G9mmFxK"
   },
   "outputs": [],
   "source": [
    "df_num.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 2)\n",
    "\n",
    "sns.boxplot(  y='QT_MAT_BAS', data=df,  orient='v' , ax=axes[0][0])\n",
    "sns.boxplot(  y='MAT_PER_MUN', data=df,  orient='v' , ax=axes[0][1]).set(yscale=\"log\")\n",
    "sns.boxplot(  y='ESC_PER_MUN', data=df,  orient='v' , ax=axes[1][0]).set(yscale=\"log\")\n",
    "sns.boxplot(  y='Age', data=df,  orient='v' , ax=axes[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 3)\n",
    "\n",
    "sns.histplot(df.QT_MAT_BAS, alpha=0.4, kde=True, kde_kws={\"cut\": 3}, ax=axes[0])\n",
    "sns.histplot(df.ESC_PER_MUN, alpha=0.4, kde=True, kde_kws={\"cut\": 3}, ax=axes[1])\n",
    "sns.histplot(df.Age, alpha=0.7, kde=True, kde_kws={\"cut\": 3}, ax=axes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "znTfs2VIDN3F"
   },
   "outputs": [],
   "source": [
    "def plot_corr(df, size=10):\n",
    "    corr = df.corr()    \n",
    "    fig, ax = plt.subplots(figsize = (size, size))\n",
    "    ax.matshow(corr)  \n",
    "    plt.xticks(range(len(corr.columns)), corr.columns) \n",
    "    plt.yticks(range(len(corr.columns)), corr.columns)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_corr(df_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE\n",
    "categ_ohe_quests = ['Q9', 'Q22', 'Q24', 'Q34', 'Q59', 'Q61', 'Q62', 'Q63',\n",
    "                    'RegiaoMetropolitana', 'SERIE_ANO', 'TP_SEXO', 'PERIODO', \n",
    "                    'Tipo_PROVA', 'disability']\n",
    "\n",
    "# Ordinals:\n",
    "\n",
    "## A < B < C < ... \n",
    "enc_greater = ['Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q19', \n",
    "               'Q20', 'Q21', 'Q27', 'Q28', 'Q29', 'Q30', 'Q31', \n",
    "               'Q35', 'Q36', 'Q37', 'Q38', 'Q39', 'Q40', 'Q41', \n",
    "               'Q50', 'Q51', 'Q52', 'Q53', 'Q54', 'Q55', 'Q56', \n",
    "               'Q57', 'Q58', 'Q60']\n",
    "\n",
    "## A > B > C > ... \n",
    "enc_lower = ['Q1', 'Q10', 'Q11', 'Q12', 'Q13', 'Q14', 'Q15', \n",
    "             'Q16','Q17', 'Q18', 'Q23', 'Q25', 'Q26', 'Q33']\n",
    "\n",
    "## Categ: A, D, B, C\n",
    "categ_ADBC = ['Q43', 'Q44', 'Q45', 'Q46', 'Q47', 'Q48', 'Q49']\n",
    "\n",
    "## Particular cases\n",
    "#'Q32'\n",
    "#'Q42' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df,\n",
    "pd.DataFrame(df[['porc_ACERT_MAT', 'porc_ACERT_CIE', 'porc_ACERT_lp','nivel_profic_lp','nivel_profic_mat','nivel_profic_cie']]),test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#O pré processamento de milhões\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler , OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#Cria um pipeline para tratar as variaveis de interesse\n",
    "df_transform = ColumnTransformer([\n",
    "    ('cat_encod', OneHotEncoder(drop = 'first'), categ_ohe_quests),\n",
    "    ('Ordinal_lower', OrdinalEncoder(categories = [['A', 'B', 'C', 'D', 'E']] * len(enc_lower)), enc_lower),\n",
    "    ('Ordinal_greater', OrdinalEncoder(categories = [['E', 'D', 'C', 'B', 'A']] * len(enc_greater)), enc_greater),\n",
    "    ('Ordinal_ADBC', OrdinalEncoder(categories = [['A', 'D', 'B', 'C']] * len(categ_ADBC)), categ_ADBC),\n",
    "    ('Ordinal_particular1', OrdinalEncoder(categories = [['D', 'A', 'B', 'C']]), ['Q32']),\n",
    "    ('Ordinal_particular2', OrdinalEncoder(categories = [['D', 'C', 'E', 'B', 'A']]), ['Q42']),\n",
    "    ('scale_robust', RobustScaler(), ['Age','QT_MAT_BAS']),\n",
    "    ('scale_max', MaxAbsScaler(), ['ESC_PER_MUN'] )   \n",
    "],\n",
    "remainder = 'drop')\n",
    "\n",
    "#Ajusta o pipeline e transforma no banco de \"treino\"\n",
    "x_train_prepared = df_transform.fit_transform(x_train)\n",
    "x_test_prepared = df_transform.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mjICojmaKQ3K"
   },
   "outputs": [],
   "source": [
    "class Manual_Regression():\n",
    "    \n",
    "    '''\n",
    "    required packages: numpy, random. \n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.train = False\n",
    "\n",
    "    def fit_normal_equation(self, X, y):\n",
    "        '''\n",
    "        inputs: X and y must be a np.array.\n",
    "        return: linear regression parameters by Normal Equation.\n",
    "        '''\n",
    "        X = np.insert(X, 0, 1, 1)\n",
    "        \n",
    "        self.train = True\n",
    "        self.thetas = np.linalg.solve(np.dot(X.T, X), np.dot(X.T, y))\n",
    "        \n",
    "        return np.linalg.solve(np.dot(X.T, X), np.dot(X.T, y))\n",
    "        \n",
    "\n",
    "    def fit_gradient(self, X, y, alpha = 0.01, iterations = 10**5, threshold = 10**(-12)):\n",
    "        \n",
    "        '''\n",
    "        inputs: X and y must be a np.array.\n",
    "        return: linear regression parameters by Gradient Descent.\n",
    "        '''\n",
    "        \n",
    "        X = np.insert(X, 0, 1, 1)\n",
    "                \n",
    "        self.thetas = np.array([np.random.normal() for i in range(X.shape[1])])\n",
    "        n = len(y)\n",
    "         \n",
    "        for k in range(iterations):\n",
    "            gradients = list()\n",
    "            cost_func = 1/(2*n) * np.sum((np.dot(X, self.thetas) - y)**2)\n",
    "\n",
    "            for j in range(len(self.thetas)):\n",
    "                gradients.append(1/n * np.sum((np.dot(X, self.thetas) - y) * X[:, j]))\n",
    "\n",
    "            aux_thetas = np.array([b - alpha*g for b, g in zip(self.thetas, gradients)])\n",
    "            new_cost_func = 1/(2*n) * np.sum((np.dot(X, aux_thetas) - y)**2) \n",
    "            self.thetas = aux_thetas\n",
    "            \n",
    "            diff_gain = new_cost_func - cost_func\n",
    "            \n",
    "            if k >= 5 and abs(diff_gain) <= threshold:\n",
    "                self.train = True\n",
    "                return self.thetas\n",
    "        \n",
    "        self.train = True\n",
    "        return self.thetas\n",
    "     \n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        '''\n",
    "        inputs: X must be a np.array.\n",
    "        return: y predicted values by the fitted model.\n",
    "        '''\n",
    "\n",
    "        if self.train:\n",
    "            X_test = np.insert(X_test, 0, 1, 1)\n",
    "            return np.dot(X_test, self.thetas)\n",
    "        else:\n",
    "            raise ValueError(\"You first must fit a linear regression model.\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4nZrMr_C2X7"
   },
   "outputs": [],
   "source": [
    "# TODO: Linear Regression. You can use scikit-learn libraries.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg_model = LinearRegression()\n",
    "reg_model_mat = reg_model.fit(np.nan_to_num(x_train_prepared), y_train['porc_ACERT_MAT'])\n",
    "reg_model_mat.intercept_, reg_model_mat.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.datasets import load_concrete\n",
    "from yellowbrick.regressor import ResidualsPlot\n",
    "\n",
    "visualizer = ResidualsPlot(reg_model, hist = False, qqplot = True)\n",
    "visualizer.fit(np.nan_to_num(x_train_prepared), y_train['porc_ACERT_MAT'])\n",
    "visualizer.score(np.nan_to_num(x_test_prepared), y_test['porc_ACERT_MAT'])\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg_model_cie = reg_model.fit(np.nan_to_num(x_train_prepared), y_train['porc_ACERT_CIE'])\n",
    "\n",
    "visualizer = ResidualsPlot(reg_model, hist = False, qqplot = True)\n",
    "visualizer.fit(np.nan_to_num(x_train_prepared), y_train['porc_ACERT_CIE'])\n",
    "visualizer.score(np.nan_to_num(x_test_prepared), y_test['porc_ACERT_CIE'])\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model_lp = reg_model.fit(np.nan_to_num(x_train_prepared), y_train['porc_ACERT_lp'])\n",
    "\n",
    "visualizer = ResidualsPlot(reg_model, hist = False, qqplot = True)\n",
    "visualizer.fit(np.nan_to_num(x_train_prepared), y_train['porc_ACERT_lp'])\n",
    "visualizer.score(np.nan_to_num(x_test_prepared), y_test['porc_ACERT_lp'])\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBNZQNImKQeo"
   },
   "source": [
    "\n",
    "> What are the conclusions? (1-2 paragraphs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADxPBRhuK_Vq"
   },
   "source": [
    "2. (1 point) Use different Gradient Descent (GD) learning rates when optimizing. Compare the GD-based solutions with Normal Equation. What are the conclusions?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RSZ1pLItNVbU"
   },
   "outputs": [],
   "source": [
    "# TODO: Gradient Descent (GD) with 3 different learning rates. You can use scikit-learn libraries.]\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgd_reg_model = SGDRegressor(max_iter = 1000, tol=1e-3, penalty=None, eta0=0.1)\n",
    "sgd_reg_model_mat = sgd_reg_model.fit(np.nan_to_num(x_train_prepared), y_train['porc_ACERT_MAT'])\n",
    "sgd_reg_model_mat.intercept_,sgd_reg_model_mat.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "\n",
    "visualizer = PredictionError(sgd_reg_model)\n",
    "visualizer.fit(np.nan_to_num(x_train_prepared), y_train['porc_ACERT_MAT'])\n",
    "visualizer.score(np.nan_to_num(x_test_prepared), y_test['porc_ACERT_MAT'])\n",
    "visualizer.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgd_reg_model2 = SGDRegressor(max_iter = 1000, tol=1e-3, penalty=None, eta0=0.01)\n",
    "sgd_reg_model2.fit(np.nan_to_num(df_prepared), df['porc_ACERT_MAT'])\n",
    "sgd_reg_model2.intercept_,sgd_reg_model2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = PredictionError(sgd_reg_model2)\n",
    "visualizer.fit(np.nan_to_num(x_train_prepared), y_train['porc_ACERT_MAT'])\n",
    "visualizer.score(np.nan_to_num(x_test_prepared), y_test['porc_ACERT_MAT'])\n",
    "visualizer.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg_model3 = SGDRegressor(max_iter = 1000, tol=1e-3, penalty=None, eta0=0.001)\n",
    "sgd_reg_model3.fit(np.nan_to_num(df_prepared), df['porc_ACERT_MAT'])\n",
    "sgd_reg_model3.intercept_,sgd_reg_model3.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = PredictionError(sgd_reg_model3)\n",
    "visualizer.fit(np.nan_to_num(x_train_prepared), y_train['porc_ACERT_MAT'])\n",
    "visualizer.score(np.nan_to_num(x_test_prepared), y_test['porc_ACERT_MAT'])\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrPl7jKgJPW6"
   },
   "source": [
    "\n",
    "3. (0.75 point) Sometimes, we need some more complex function to make good prediction. Devise and evaluate a Polynomial Linear Regression model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GjGbg41PMHR9"
   },
   "outputs": [],
   "source": [
    "# TODO: Complex model. You can use scikit-learn libraries.\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_prep = PolynomialFeatures(degree=3, include_bias=False)\n",
    "\n",
    "x_poly_prep = poly_prep.fit_transform(x_train_prepared)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBLKtosaLaCw"
   },
   "source": [
    "*texto em itálico*\n",
    " > What are the conclusions? What are the actions after such analyses? (1-2 paragraphs)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldSh1vtWK5Zk"
   },
   "source": [
    "4. (0.5) Plot the cost function vs. number of epochs in the training/validation set and analyze the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mg7aNkl_LG4P"
   },
   "outputs": [],
   "source": [
    "# TODO: Plot the cost function vs. number of iterations in the training set.\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def plot_cost_functio(X, y, epochs, learning_rate):\n",
    "    X_train2, X_val,Y_train2, Y_val = train_test_split(X, y, test_size=0.2)\n",
    "    train_error, val_error = [], []\n",
    "    for epoch in range(1,epochs):\n",
    "        model = SGDRegressor(max_iter = epoch, tol=1e-3, penalty=None, eta0= learning_rate)\n",
    "        model.fit(X_train2,Y_train2)\n",
    "        y_train2_predict = model.predict(X_train2)\n",
    "        y_val_predict = model.predict(X_val)\n",
    "        train_error.append(mean_squared_error(Y_train2,y_train2_predict))\n",
    "        val_error.append(mean_squared_error(Y_val,y_val_predict))\n",
    "        font = {'family': 'serif',\n",
    "        'color':  'darkblue',\n",
    "        'weight': 'normal',\n",
    "        'size': 12,\n",
    "        }\n",
    "    plt.plot(train_error,\"g-\", linewidth=1, label=\"Train\")\n",
    "    plt.plot(val_error,\"r:\", linewidth=2, label=\"Val\")\n",
    "    plt.title(\"Cost Function per Epoch size\",fontdict= font)\n",
    "    plt.xlabel(\"Number of Epochs\",fontdict= font)\n",
    "    plt.ylabel(\"MSE\",fontdict=font)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "plot_cost_functio(np.nan_to_num(x_train_prepared), y_train['porc_ACERT_MAT'], 20, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "plot_cost_functio(np.nan_to_num(x_train_prepared), y_train['porc_ACERT_MAT'], 20, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_cost_functio(np.nan_to_num(x_train_prepared), y_train['porc_ACERT_MAT'], 20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_cost_functio(np.nan_to_num(x_train_prepared), y_train['porc_ACERT_MAT'], 20, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CfR862UoK9j6"
   },
   "outputs": [],
   "source": [
    "*texto em itálico*\n",
    " > What are the conclusions? What are the actions after such analyses? (1-2 paragraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Xij-E5UUseS"
   },
   "source": [
    "5. (0.25 point) Pick **your best model**, based on your validation set, and predict the target values for the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_PobUahUseS"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SCJuwjrAUseS"
   },
   "source": [
    "Now, this part of the assignment aims to predict students' proeficiency level on Portuguese, Mathematics, and Natural Sciences (target values: `nivel_profic_lp`, `nivel_profic_mat` and `nivel_profic_cie`) based on their socioeconomic data. Then, you have to **drop the columns `porc_ACERT_lp`,  `porc_ACERT_MAT`** and  **`porc_ACERT_CIE`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joYtn8avUseS"
   },
   "source": [
    "### Activities\n",
    "\n",
    "1. (2.75 points) Perform Multinomial Logistic Regression (_i.e._, softmax regression). It is a generalization of Logistic Regression to the case where we want to handle multiple classes. Try different combinations of features, dropping the ones less correlated to the target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-36Dt2V_UseT"
   },
   "outputs": [],
   "source": [
    "# TODO: Multinomial Logistic Regression. You can use scikit-learn libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQj3oImUUseT"
   },
   "source": [
    "> What are the conclusions? (1-2 paragraphs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yb1KNEqLUseT"
   },
   "source": [
    "2. (0.5 point) Plot the cost function vs. number of epochs in the training/validation set and analyze the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfECeHi3UseT"
   },
   "outputs": [],
   "source": [
    "# TODO: Plot the cost function vs. number of iterations in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-IM4mx23UseT"
   },
   "source": [
    "> What are the conclusions? (1-2 paragraphs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lqlv9-6OUseT"
   },
   "source": [
    "3. (0.75 point) Pick **your best model** and plot the confusion matrix in the **test set**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-jdyJuS0UseT"
   },
   "outputs": [],
   "source": [
    "# TODO: Plot the confusion matrix. You can use scikit-learn, seaborn, matplotlib libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAmCj0cpUseT"
   },
   "source": [
    "> What are the conclusions? (1-2 paragraphs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdSGS4brHnAi"
   },
   "source": [
    "## Deadline\n",
    "\n",
    "Monday, September 19, 11:59 pm. \n",
    "\n",
    "Penalty policy for late submission: You are not encouraged to submit your assignment after due date. However, in case you do, your grade will be penalized as follows:\n",
    "- September 20, 11:59 pm : grade * 0.75\n",
    "- September 21, 11:59 pm : grade * 0.5\n",
    "- September 22, 11:59 pm : grade * 0.25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joN9pvZJIfW5"
   },
   "source": [
    "## Submission\n",
    "\n",
    "On Google Classroom, submit your Jupyter Notebook (in Portuguese or English).\n",
    "\n",
    "**This activity is NOT individual, it must be done in pairs (two-person group).**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
